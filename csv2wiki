#!/usr/bin/env python
#
# Convert a CSV file to wiki pages.  Run 'csv2wiki --help' for details.
# https://github.com/OpenTechStrategies/ots-tools/blob/master/csv2wiki
#
# Copyright (C) 2017 Open Tech Strategies, LLC
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as published
# by the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program. If not, see <http://www.gnu.org/licenses/>.

# It would be simple to change the main() function to accept a different
# url via user input.
#
# TODO: add a wrapper class to take different wiki types

import csv
from mwclient import Site
from mwclient import errors
import getopt, sys
import ConfigParser

# For exception matching.
import requests

def create_pages(config_obj):
    """
    Create one wiki page for each line in a CSV file supplied from the
    configuration settings.  The CSV should have a header row and at
    least one row of content.

    Connect to the wiki site using the url, username, and password given
    in the configuration settings.

    """
    csv_file = config_obj['source_filename']
    wiki_url = config_obj['wiki_url']
    username = config_obj['username']
    password = config_obj['password']

    try:
        site = Site(wiki_url.split("://"), path=config_obj['path_to_api'],)
    except requests.exceptions.HTTPError as err: 
        sys.stderr.write("ERROR: failed to connect to wiki URL '%s'\n" % wiki_url)
        sys.stderr.write("       Error details:\n")
        sys.stderr.write("       ('%s')\n" % err)
        sys.exit(1)

    try:
        site.login(username, password)
    except errors.LoginError as err:
        sys.stderr.write("ERROR: Unable to log in to wiki; "
                         "check that username and password are correct.\n")
        sys.stderr.write("       Error details:\n")
        sys.stderr.write("       ('%s')\n" % err)
        sys.exit(1)

    toc_page = site.pages[config_obj['toc_name']]
    toc_text = ""
    categories = []
    
    # read in csv
    with open(csv_file, 'rb') as csvfile:
        reader = csv.reader(csvfile, delimiter=config_obj['delimiter'], quotechar=config_obj['quotechar'])
        is_header = True
        row_num = 0
        for row in reader:
            if is_header:
                # if this is the first row, save headers
                header_array = []
                for cell in row:
                    header_array.append(cell)
                is_header = False
            else:
                # Looping over the cells in the row.  Name the sections
                # according to headers.
                cell_num = 0
                for cell in row:
                    if cell_num == 0:
                        # For this new line, generate a mediawiki page
                        # TODO: use the config obj properly to make the title
                        title = 'Proposal_'+ str(row_num) + ': ' + cell
                        print("CREATING: " + title)
                        page = site.pages[title]
                        # Add the new page to the list of pages
                        toc_text += '* [[' + title + ']] \n'
                        # Set the contents of each cell to their own section.
                    if cell is not "":
                        # A section can only be created with some text
                        #
                        if cell_num == int(config_obj['cat_col']):
                            # For the last column, create a category (NOTE:
                            # this is overly customized to a certain set of
                            # CSVs; feel free to remove this conditional for
                            # other CSVs)
                            cell_text = '[[Category:' + cell + ']]'
                            
                            # Add this to the list of categories, unless
                            # it's already there:
                            if cell not in categories:
                                categories.append(cell)
                        else:
                            cell_text = cell
                            # TODO: it's probably bad practice to save each page
                            # many times, and it's definitely slowing down the
                            # script.
                            #
                            # What's the deal with save/edit/text?  Send
                            # just one API request per page.
                        try:
                            page.save(cell_text, section=cell_num, sectiontitle=header_array[cell_num])
                        except errors.APIError:
                            page.save(cell_text, section='new', sectiontitle=header_array[cell_num])
                        # TODO: need a generic 'except' case for if we
                        # get an error we don't know how to handle
                        # (i.e., something other than errors.APIError).
                        # If that happens, this function should return
                        # some value to its caller (which is main())
                        # to indicate that an error has happened;
                        # otherwise the return value should be None or
                        # some other empty "everything is okay" flag.
                        # In addition to setting a return-error flag
                        # here, it would be okay to print to stderr
                        # here something about the unhandled error.
                                
                    cell_num += 1

            row_num += 1
        
    # create the TOC page.
    toc_page.save(toc_text)
    
    # generate the category pages
    for category in categories:
        print("CREATING CATEGORY: " + category)
        page_title = 'Category:' + category
        page = site.pages[page_title]
        page.save("")

    return

def delete_pages(config_obj):
    """
    Delete wiki pages matching a search string given in the configuration
    file.  Connect to the site using the url, username, and password in
    that file.
    """
    wiki_url = config_obj['wiki_url']
    username = config_obj['username']
    password = config_obj['password']
    search_string=config_obj['search_string']
    
    site = Site(wiki_url.split("://"), path=config_obj['path_to_api'],)
    site.login(username, password)
    
    search_result = site.search(search_string)
    for result in search_result:
        # get as a page
        print("DELETING: " + result['title'])
        page = site.pages[result['title']]
        # delete with extreme prejudice
        page.delete()

    return

def usage(errout=False):
    """Print a message explaining how to use this script.
    Print to stdout, unless ERROUT, in which case print to stderr."""
    out = sys.stderr if errout else sys.stdout
    out.write("""Convert each entry (row) in a CSV file to a MediaWiki page.

Basic usage:

  $ csv2wiki -f CONFIG_FILE CSV_FILE 

The CONFIG_FILE contains the wiki URL, login information, and various
other run-time parameters.  It is in standard .ini file format, with
the following elements:

  wiki_url:      The url of the wiki, e.g. "http://localhost/mediawiki",
                 "https://www.example.com/mwiki", etc.

  path_to_api:   The API path under the URL.  Defaults to "/w/".  (See
                 http://mwclient.readthedocs.io/en/master/user/connecting.html.)

  username:      User account that has write/create permission in the wiki.
                 (With --delete option, user needs page-delete permission.)

  password:      The wiki password corresponding to the username.

  csv_input:     Path to the CSV input file.

  toc_name:      Title for the generated Table of Contents page.

  cat_col:       The number of the column (if any) in the CSV file that
                 should be used to create a category for that row;
                 column numbering begins at 1, not 0.  Omit this, or
                 leave the value blank, to not use categories at all.

  delimiter:     A single-char delimiter used to separate columns in
                 a CSV row.  If omitted, defaults to ','.

  quotechar:     A single-char quotechar used to wrap contents of a
                 single cell in the CSV file.  If omitted, defaults
                 to '"'.

  page_title:    TBD

Example config file
-------------------

In this example config file, the "[csv2wiki]" section name at the top
is ignored -- it could be any value; the .ini format insists on
it, but this script doesn't (currently) use it.

  [csv2wiki]
  wiki_url: http://localhost/mediawiki
  path_to_api: /
  username: wikibot
  password: wikibot1
  source_filename: /path/to/input.csv
  toc_name: List_of_Proposals
  cat_col: 5
  delimiter: ,
  quotechar: "
  page_title: Proposal

Page deletion support
---------------------

This script also supports batch deletion of pages, since a possible
outcome of initial runs is that you have a bunch of pages in your wiki
that turn out to be not ready.  To remove them, pass the "--delete"
option and use this additional parameter in the config file:

  search_string: When used with the --delete option, delete all
                 pages whose names match this string.  This
                 parameter has no effect without "--delete".
                 Typically, search_string will be similar to
                 page_title, since it is being used to delete
                 pages originally created with this script.

                 TODO: We will probably change --delete to just
                 re-calculate page titles based on the CSV
                 input, instead of using search_string to query
                 the MediaWiki API for a list of pages.  This
                 change will make search_string obsolete.

Dependencies and Troubleshooting
--------------------------------

* You will need to install the 'mwclient' Python library.

  If you get an error that looks something like this:

    Traceback (most recent call last):
      File "./csv2wiki", line 27, in <module>
        from xmwclient import Site
    ImportError: No module named xmwclient

  then do 'pip install mwclient' and try again.

* If you run create/delete multiple times, you may need to run
  
    $ php maintenance/rebuildall.php
  
  in your MediaWiki instance to link pages to their categories properly.
  That script takes about 10 minutes to run for a wiki with <300 pages.
  
* If you get errors saving some pages, it may be an anti-spam plugin.
  
  If your MediaWiki instance has Extension:SpamBlacklist enabled,
  then you may get errors when trying to create pages that contain
  certain kinds of URLs or email addresses (namely, URLs or email
  addresses that SpamBlacklist thinks look spammy). 
  
  One solution is to just turn off Extension:SpamBlacklist entirely.
  But even if you don't have that kind of administrative access,
  you might still have enough access to *configure* the extension, 
  in which case you can whitelist everything via a catchall regexp.
  Visit one or of of these pages:
  
    https://mywiki.example.com/index.php?title=MediaWiki:Spam-whitelist
    https://mywiki.example.com/index.php?title=MediaWiki:Email-whitelist
  
  You'll see a commented-out explanation of how the whitelist works.
  Just add a line with the regular expression ".*", as in this example:
  
    # External URLs matching this list will *not* be blocked even if they would
    # have been blocked by blacklist entries.
    #
    # Syntax is as follows:
    #   * Everything from a "#" character to the end of the line is a comment
    #   * Every non-blank line is a regex fragment which will only match hosts inside URLs
    .*
  
  That will let you save a page containing any URL.  (Things work
  similarly on the Email-whitelist page).

* Run time may be slower than you expect.

  Creating 250 wiki pages takes about 5 minutes on localhost.  
  Part of the reason for this is that the script does a page save
  for every section within a page; see the TODO comment near the 
  page.save() calls in the loop over cells for more.  We may look
  into whether the 'mwclient' library offers a caching option, or
  maybe we'll create the whole page and save it once at the end.
""")

def parse_config_file(config_file):
    """
    Parse a CONFIG_FILE into configuration parameters for use in other functions.
    """
    config_obj = {}
    config = ConfigParser.ConfigParser()
    config.read(config_file)
    for section in config.sections():
        for option in config.options(section):
            config_obj[option] = config.get(section, option)

    return config_obj

def main():
    """
    By default, creates wiki pages from a supplied CSV.  Optionally,
    deletes those pages instead.

    """
    try:
        opts, args = getopt.getopt(sys.argv[1:], 'h?df:', ("help", "usage", "delete", "file="))
    except getopt.GetoptError as err:
        sys.stderr.write("ERROR: '%s'\n" % err)
        usage(errout=True)
        sys.exit(2)

    filename = None
    delete = False
    bad_opt_seen = False
    for o, a in opts:
        if o in ("-h", "-?", "--help", "--usage"):
            usage()
            sys.exit(0)
        elif o in ("-d", "--delete"):
            delete = True
        elif o in ("-f", "--file"):
            filename = a
        else:
            sys.stderr.write("ERROR: unrecognized option '%s'\n" % o)
            bad_opt_seen = True

    if bad_opt_seen:
        sys.exit(2)

    if filename is None:
        sys.stderr.write("ERROR: missing config file; use -f to supply it\n")
        usage(errout=True)
        sys.exit(2)
    else:
        config_settings = parse_config_file(filename)

    if delete:
        try:
            delete_pages(config_settings)
        except IndexError as err:
            sys.stderr.write("ERROR: '%s'\n" % err)
            usage(errout=True)
            sys.exit(1)
    else:
        try:
            create_pages(config_settings)
        except IndexError as err:
            sys.stderr.write("ERROR: '%s'\n" % err)
            usage(errout=True)
            sys.exit(1)


if __name__ == '__main__':
    main()
